{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3991f2c",
   "metadata": {},
   "source": [
    "# **Group 13**:\n",
    "Evan Garcia, Jacob Ramos, Casey Kwinn, Daniel Cook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a44b2c",
   "metadata": {},
   "source": [
    "# **Project**: Traffic Volume\n",
    "\n",
    "Traffic is a daily dilemma that most people face in their life way too many times. The average driver in America spends 293 hrs annually behind the wheel.\n",
    "\n",
    "Our group goal is to predict metro traffic volume based on:\n",
    "Hourly weather features, \n",
    "Temperature,\n",
    "Holidays,\n",
    " & Date/Time.\n",
    "\n",
    "We will use a dataset that contains the number of instances of metro traffic during different conditions and features. We want to run and use different regression models to measure and figure out what attributes/features causes the most noticeable effect in traffic. Some techniques we plan to use are the K-Mean Clustering and Cross-Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed107ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "df = pd.read_csv(\"Metro_Interstate_Traffic_Volume.csv\")\n",
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd0430",
   "metadata": {},
   "source": [
    "This is our graph that has 9 columns: Holiday, Temp, Rain1Hour, Snow1Hour, CloudAll, MainWeather, WeatherDescription, DateTime, and TrafficVolume. To start our EDA, we first want to figure out how many unique values there are in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0510d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df\n",
    "df2.nunique(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a96c5",
   "metadata": {},
   "source": [
    "We are now checking the means, count, min, max, and more about this dataset and put it in scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1587a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe().apply(lambda s: s.apply(lambda x: format(x, 'f')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0412a19",
   "metadata": {},
   "source": [
    "To go further in examining the data, we will focus on getting a better understanding of the variables and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e5463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.weather_main.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7669b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.snow_1h.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f8cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.holiday.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.clouds_all.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c937b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.weather_description.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d8a48",
   "metadata": {},
   "source": [
    "While examining the unique values, one thing we notice in weather description is that some of it is similar to each other, such as 'thunderstorm with light drizzle' and 'thunderstorm with drizzle'. This is redundant and we want to reclassify some of these descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6356bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather_description(row):\n",
    "    \n",
    "    simplifythunderstormrain = ['thunderstorm with light rain', 'thunderstorm with rain', 'thunderstorm with heavy rain' ]\n",
    "    simplifythunderstormdrizzle = ['thunderstorm with drizzle', 'thunderstorm with light drizzle']\n",
    "    simplifydrizzle = ['light intensity drizzle', 'drizzle', 'heavy intensity drizzle']\n",
    "    simplifyskyclear = ['sky is clear','Sky is Clear']\n",
    "    simplifyheavyrain = ['heavy intensity rain', 'very heavy rain']\n",
    "    simplifylightsnow = ['light shower snow', 'light snow']\n",
    "    simplifyshowerrain = ['proximity shower rain', 'shower rain', 'light intensity shower rain']\n",
    "    simplifysquall = ['freezing rain', 'light rain and snow', 'SQUALLS']\n",
    "    \n",
    "    if row.weather_description in simplifythunderstormrain:\n",
    "        return 'thunderstorm with rain'   \n",
    "    if row.weather_description in simplifythunderstormdrizzle:\n",
    "        return 'thunderstorm with drizzle' \n",
    "    if row.weather_description in simplifydrizzle:\n",
    "        return 'drizzle' \n",
    "    if row.weather_description in simplifyskyclear:\n",
    "        return 'clear'\n",
    "    if row.weather_description in simplifyheavyrain:\n",
    "        return 'heavy rain'\n",
    "    if row.weather_description in simplifylightsnow:\n",
    "        return 'light snow'\n",
    "    if row.weather_description in simplifyshowerrain:\n",
    "        return 'shower rain'\n",
    "    if row.weather_description in simplifysquall:\n",
    "        return 'squall'\n",
    "    return row.weather_description # Clean dataframe\n",
    "def clean_df(playlist):\n",
    "    df_cleaned = df2.copy()\n",
    "    df_cleaned['weather_description'] = df_cleaned.apply(lambda row: clean_weather_description(row), axis=1)\n",
    "    return df_cleaned# Get df with reclassfied 'condition' column\n",
    "df_cleaned = clean_df(df2)\n",
    "df_cleaned.weather_description.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf74f4",
   "metadata": {},
   "source": [
    "As shown, we reduced some of the variables that were redundant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3160d59a",
   "metadata": {},
   "source": [
    "Going through the dataset, we realize that the columns of rain and snow 1 hour on the cluster graphs we made have very little use or info to extract from because most of the time the column is equal to 0. So we will rid of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627749ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.copy().drop(['rain_1h','snow_1h'], axis=1)\n",
    "df_cleaned.nunique(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569f215",
   "metadata": {},
   "source": [
    "Now the next step in the EDA is to rid of some outliers, like in the temp category and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45742c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned[df_cleaned['temp'].between(250.00, 312.00)]\n",
    "df_cleaned = df_cleaned[df_cleaned['traffic_volume'] > 1000]\n",
    "df_cleaned = df_cleaned[df_cleaned['date_time'] > '2013-12-31 23:00:00']\n",
    "\n",
    "column_to_move = df_cleaned.pop('traffic_volume')\n",
    "df_cleaned.insert(0, 'traffic_volume', column_to_move)\n",
    "df_cleaned[['date' ,'time']] = df_cleaned.date_time.str.split(expand=True)\n",
    "df_cleaned = df_cleaned.drop('date_time', axis=1)\n",
    "\n",
    "df_cleaned.describe().apply(lambda s: s.apply(lambda x: format(x, 'f')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f837d",
   "metadata": {},
   "source": [
    "Now we will see the brand new cleaned dataset that we will work with on the main part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bc5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99664b8",
   "metadata": {},
   "source": [
    "Now that the dataset has been cleaned we can perform some basic exploratory data analysis to see what we're dealing with. We can start with some bar graphs showing the correleation between traffic volume and the other variables in the dataset.\n",
    "\n",
    "To start, it seems like holidays have, on average, significantly lower traffic volume than non-holidays. Although this makes sense, the dataset only contains several entries of holidays, so the sample size isn't very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281db620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt = df_cleaned.pivot_table(values='traffic_volume',index='holiday',aggfunc=np.mean)\n",
    "df_pt.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444267a8",
   "metadata": {},
   "source": [
    "Next, it appears that temperature and cloud coverage have little affect on traffic volume, although the does seem to be a small correlation between lower temperature and lower traffic volume on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8fb5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt2 = df_cleaned\n",
    "df_pt2['temp_range'] = pd.cut(x=df_pt2['temp'], bins=[250,255,260,265,270,275,280,285,290])\n",
    "df_pt2.pivot_table(values='traffic_volume',index='temp_range',aggfunc=np.mean).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt3 = df_cleaned\n",
    "df_pt3['clouds_range'] = pd.cut(x=df_pt3['clouds_all'], bins=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "#df_pt3['clouds_range'].value_counts()\n",
    "df_pt3.pivot_table(values='traffic_volume',index='clouds_range',aggfunc=np.mean).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt4 = df_cleaned.pivot_table(values='traffic_volume',index='weather_main',aggfunc=np.mean)\n",
    "df_pt4.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e3f9f",
   "metadata": {},
   "source": [
    "As for weather, there tends to be lower traffic volume during light and heavy snowfall, whereas traffic volume seems mostly unaffected by other weather patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt5 = df_cleaned.pivot_table(values='traffic_volume',index='weather_description',aggfunc=np.mean)\n",
    "df_pt5.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c7267",
   "metadata": {},
   "source": [
    "Finally, time of day seems to have a very obvious impact on traffic volume. Late hours of the night have very reduced traffic volume, where as working hours of the day have much higher volume, with peaks occuring at the start and end hours of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9bf7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt6 = df_cleaned.pivot_table(values='traffic_volume',index='time',aggfunc=np.mean)\n",
    "df_pt6.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8487303",
   "metadata": {},
   "source": [
    "## **Main Part**\n",
    "\n",
    "For our project, we are going to use K-Mean Clustering on our dataset to find clusters that show the attributes that have the most influence on metropolitan traffic. (Just testing and messing with data) **Ignore for now, still cleaning dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c898d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab469a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f921b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caddff25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46070b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7232ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5851b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccfcc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f451ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['temp', 'traffic_volume']].copy()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bccf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean = KMeans(3)\n",
    "kmean.fit(x)\n",
    "identified_clusters = kmean.fit_predict(x)\n",
    "identified_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_clusters = df.copy()\n",
    "data_with_clusters['Clusters'] = identified_clusters \n",
    "plt.scatter(data_with_clusters['temp'],data_with_clusters['traffic_volume'],c=data_with_clusters['Clusters'],cmap='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513fb06",
   "metadata": {},
   "source": [
    "This is just to see if a elbow test can work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb3a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(1,7):\n",
    "    kmean = KMeans(i)\n",
    "    kmean.fit(x)\n",
    "    wcss_iter = kmean.inertia_\n",
    "    wcss.append(wcss_iter)\n",
    "\n",
    "number_clusters = range(1,7)\n",
    "plt.plot(number_clusters,wcss)\n",
    "plt.title('The Elbow title')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad573eb0",
   "metadata": {},
   "source": [
    "did temp and traffic, now clouds and traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['clouds_all', 'traffic_volume']].copy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e19903",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean2 = KMeans(3)\n",
    "kmean2.fit(y)\n",
    "identified_clusters2 = kmean2.fit_predict(y)\n",
    "identified_clusters2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3668a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_clusters2 = df.copy()\n",
    "data_with_clusters2['Clusters'] = identified_clusters2 \n",
    "plt.scatter(data_with_clusters2['clouds_all'],data_with_clusters2['traffic_volume'],c=data_with_clusters2['Clusters'],cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f436b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['traffic_volume'] = df['traffic_volume'].astype(float)\n",
    "#kmeans = KMeans(n_clusters=3, random_state=0).fit(df['traffic_volume'])\n",
    "\n",
    "# add the cluster labels to the dataframe\n",
    "#df['traffic_level'] = kmeans.labels_\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# reshape the data to have two dimensions\n",
    "data = np.array(df['traffic_volume']).reshape(-1, 1)\n",
    "sorted_data = np.sort(df['traffic_volume'])\n",
    "initial_centroids = np.array([\n",
    "    [sorted_data[int(0 * len(sorted_data) / 100)]],\n",
    "    [sorted_data[int(50 * len(sorted_data) / 100)]],\n",
    "    [sorted_data[int(100 * (len(sorted_data)-1) / 100)]]\n",
    "])\n",
    "\n",
    "# fit KMeans model with specified initial centroids\n",
    "kmeans = KMeans(n_clusters=3, init=initial_centroids).fit(data)\n",
    "\n",
    "# add the cluster labels to the dataframe\n",
    "df['traffic_level'] = kmeans.labels_\n",
    "print(df[['traffic_level', 'traffic_volume']])\n",
    "# sort the DataFrame by 'traffic_volume' column\n",
    "df = df.sort_values('traffic_volume')\n",
    "\n",
    "# normalize the 'traffic_volume' column between 0 and 1\n",
    "df['normalized_traffic_volume'] = (df['traffic_volume'] - df['traffic_volume'].min()) / (df['traffic_volume'].max() - df['traffic_volume'].min())\n",
    "\n",
    "# plot the line chart\n",
    "plt.plot(df['normalized_traffic_volume'], df['traffic_level'])\n",
    "plt.xlabel('Normalized Traffic Volume')\n",
    "plt.ylabel('Traffic Level')\n",
    "plt.title('Traffic Level vs. Normalized Traffic Volume')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34cb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = df[['rain_1h', 'traffic_volume']].copy()\n",
    "rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaaa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean3 = KMeans(3)\n",
    "kmean3.fit(rain)\n",
    "identified_clusters3 = kmean3.fit_predict(rain)\n",
    "data_with_clusters3 = df.copy()\n",
    "data_with_clusters3['Clusters'] = identified_clusters3\n",
    "plt.scatter(data_with_clusters3['rain_1h'],data_with_clusters3['traffic_volume'],c=data_with_clusters3['Clusters'],cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = df[['snow_1h', 'traffic_volume']].copy()\n",
    "snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean4 = KMeans(3)\n",
    "kmean4.fit(snow)\n",
    "identified_clusters4 = kmean4.fit_predict(rain)\n",
    "data_with_clusters4 = df.copy()\n",
    "data_with_clusters4['Clusters'] = identified_clusters4\n",
    "plt.scatter(data_with_clusters4['snow_1h'],data_with_clusters4['traffic_volume'],c=data_with_clusters4['Clusters'],cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e2cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df[['date_time', 'traffic_volume']].copy()\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c64fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8134c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
